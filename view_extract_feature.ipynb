{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24212ca9-55b3-46de-894e-2a4f74c87c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import openslide\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0826771d-475f-4e79-898b-87263b165812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于Jupyter Notebook，适配路径获取方式\n",
    "try:\n",
    "    # 获取当前笔记本文件的路径\n",
    "    project_root = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "    sys.path.append(project_root)\n",
    "except NameError:\n",
    "    # 如果失败，使用当前工作目录\n",
    "    project_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48792099-1417-43d8-abfe-c94a7c50966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import WSIPatchDataset \n",
    "from models.swin_unet import SwinBackbone\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724b26ff-5a3e-45f4-80ec-6f81df290eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_loader(\n",
    "    wsi_path,\n",
    "    patch_size=256,\n",
    "    stride=256,\n",
    "    level=0,\n",
    "    batch_size=16,\n",
    "    num_workers=8,  # 增加工作进程数，适应多卡\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    "):\n",
    "    dataset = WSIPatchDataset(\n",
    "        wsi_path=wsi_path,\n",
    "        patch_size=patch_size,\n",
    "        stride=stride,\n",
    "        level=level\n",
    "    )\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d325bd-a7c4-48e8-8021-7178ad02b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, backbone):\n",
    "        # 检查可用GPU数量\n",
    "        self.num_gpus = torch.cuda.device_count()\n",
    "        print(f\"发现 {self.num_gpus} 个可用GPU\")\n",
    "        \n",
    "        # 使用DataParallel实现多卡并行\n",
    "        if self.num_gpus > 1:\n",
    "            self.backbone = nn.DataParallel(backbone).cuda()\n",
    "        else:\n",
    "            self.backbone = backbone.cuda()\n",
    "            \n",
    "        self.backbone.eval()\n",
    "\n",
    "    def extract(self, loader):\n",
    "        features_list = []\n",
    "        coords_list = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 增加进度条显示\n",
    "            for imgs, coords in tqdm(loader, desc=\"提取特征\"):\n",
    "                # 自动分配到多个GPU\n",
    "                imgs = imgs.cuda(non_blocking=True)\n",
    "                feats = self.backbone(imgs)  # 输出形状 [B, C, H', W'] 或 [B, L, C]\n",
    "                features_list.append(feats.cpu())\n",
    "                coords_list.append(coords)\n",
    "\n",
    "        features = torch.cat(features_list, dim=0)\n",
    "        coords = torch.cat(coords_list, dim=0)\n",
    "        return features, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4b1bb-1031-40ba-8639-c5eee590a353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现 8 个可用GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from WSI:   0%|                                                                                                               | 0/10615 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    wsi_dir = '/mnt/gemlab_data_2/User_database/zhushiwei/PHASE/train_images'\n",
    "    save_dir = '/mnt/gemlab_data_2/User_database/zhushiwei/PHASE/test_PreceptGuide'\n",
    "    features_dir = os.path.join(save_dir, 'features')\n",
    "    coords_dir = os.path.join(save_dir, 'coords')\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "    os.makedirs(coords_dir, exist_ok=True)\n",
    "    \n",
    "    # 初始化骨干模型\n",
    "    backbone = SwinBackbone(\n",
    "        model_name=\"swin_base_patch4_window7_224\",\n",
    "        pretrained=True,\n",
    "        out_indices=(3,)\n",
    "    )\n",
    "\n",
    "    # 初始化特征提取器（多卡支持）\n",
    "    feature_extractor = FeatureExtractor(backbone)\n",
    "    \n",
    "    # 遍历每一张 WSI（假设为 .tiff）\n",
    "    wsi_files = [f for f in os.listdir(wsi_dir) if f.endswith('.tiff') ]\n",
    "    for wsi_filename in tqdm(wsi_files, desc='Extracting features from WSI'):\n",
    "        wsi_path = os.path.join(wsi_dir, wsi_filename)\n",
    "        wsi_name = os.path.splitext(wsi_filename)[0]\n",
    "        features_path = os.path.join(features_dir, f'{wsi_name}.pt')\n",
    "        coords_path = os.path.join(coords_dir, f'{wsi_name}.pt')\n",
    "        \n",
    "        if os.path.exists(features_path) and os.path.exists(coords_path):\n",
    "            print(f'Skipping {wsi_name}, features already extracted.')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # 根据GPU数量调整batch_size，每个GPU处理32个样本\n",
    "            batch_size = 32 * feature_extractor.num_gpus\n",
    "            loader = get_wsi_loader(\n",
    "                wsi_path=wsi_path,\n",
    "                patch_size=256,\n",
    "                stride=256,\n",
    "                level=0,\n",
    "                batch_size=batch_size,\n",
    "                num_workers=8,\n",
    "                pin_memory=True\n",
    "            )\n",
    "            \n",
    "            # 使用多卡提取特征\n",
    "            features, coords = feature_extractor.extract(loader)\n",
    "            \n",
    "            # 保存特征和坐标\n",
    "            torch.save(features, features_path)\n",
    "            torch.save(coords, coords_path)\n",
    "\n",
    "            print(f'WSI: {wsi_name}')\n",
    "            print(f'Features shape: {features.shape}')\n",
    "            print(f'Coords shape: {coords.shape}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'处理 {wsi_name} 时出错: {str(e)}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fec84b-6b58-4504-8c7b-1e73d2644023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询时间: 2025-08-17 12:58:37\n",
      "\n",
      "显卡ID    CUDA设备      PID       显存(MB)      运行时间              进程信息\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "0       cuda:0      1806048   15986       3天20时44分30秒       python train.py /home/xh/711/config_files/config12.yaml\n",
      "0       cuda:0      3684605   2840        15时48分52秒         python tools/train.py --config configs/exp_a_deformable_attention_head.py --work-dir ./work_dirs/ablations/T1_Baseline --cfg-options randomness.seed=42 resume=True model.use_backbone=False model.use_neck=False model.use_high_freq_enhancement=False model.decode_head.use_feature_fusion=False model.decode_head.use_deformable_conv=False model.decode_head.use_semantic_guidance=False model.decode_head.use_progressive_upsampling=False\n",
      "1       cuda:1      3691050   29064       15时46分26秒         python tools/train.py --config configs/exp_a_deformable_attention_head.py --work-dir ./work_dirs/ablations/T1_Baseline_Backbone --cfg-options randomness.seed=42 resume=True model.use_backbone=True model.use_neck=False model.use_high_freq_enhancement=False model.decode_head.use_feature_fusion=False model.decode_head.use_deformable_conv=False model.decode_head.use_semantic_guidance=False model.decode_head.use_progressive_upsampling=False\n",
      "2       cuda:2      3694257   29142       15时45分11秒         python tools/train.py --config configs/exp_a_deformable_attention_head.py --work-dir ./work_dirs/ablations/T1_Baseline_Backbone_Neck --cfg-options randomness.seed=42 resume=True model.use_backbone=True model.use_neck=True model.use_high_freq_enhancement=False model.decode_head.use_feature_fusion=False model.decode_head.use_deformable_conv=False model.decode_head.use_semantic_guidance=False model.decode_head.use_progressive_upsampling=False\n",
      "3       cuda:3      3698790   29142       15时43分24秒         python tools/train.py --config configs/exp_a_deformable_attention_head.py --work-dir ./work_dirs/ablations/T1_Baseline_FeatureFusion --cfg-options randomness.seed=42 resume=True model.use_backbone=True model.use_neck=True model.use_high_freq_enhancement=False model.decode_head.use_feature_fusion=True model.decode_head.use_deformable_conv=False model.decode_head.use_semantic_guidance=False model.decode_head.use_progressive_upsampling=False\n",
      "4       cuda:4      2988292   35656       3天12时12分18秒       /home/sun/miniconda3/envs/xxh2/bin/python3.11 -u /home/sun/XieXingHe/CV_generation/zero_1/train/train_gpt.py\n",
      "5       cuda:5      2988293   35656       3天12时12分18秒       /home/sun/miniconda3/envs/xxh2/bin/python3.11 -u /home/sun/XieXingHe/CV_generation/zero_1/train/train_gpt.py\n",
      "6       cuda:6      2988294   35656       3天12时12分18秒       /home/sun/miniconda3/envs/xxh2/bin/python3.11 -u /home/sun/XieXingHe/CV_generation/zero_1/train/train_gpt.py\n",
      "7       cuda:7      2988295   35656       3天12时12分18秒       /home/sun/miniconda3/envs/xxh2/bin/python3.11 -u /home/sun/XieXingHe/CV_generation/zero_1/train/train_gpt.py\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_gpu_processes():\n",
    "    \"\"\"获取占用GPU显存的进程信息\"\"\"\n",
    "    try:\n",
    "        # 使用更兼容的查询方式\n",
    "        result = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-compute-apps=pid,used_memory,gpu_uuid\", \n",
    "             \"--format=csv,noheader,nounits\"],\n",
    "            stderr=subprocess.STDOUT,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        processes = []\n",
    "        for line in result.decode('utf-8').strip().split('\\n'):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            parts = [p.strip() for p in line.split(',')]\n",
    "            if len(parts) >= 3:\n",
    "                try:\n",
    "                    pid = int(parts[0])\n",
    "                    memory = int(parts[1])\n",
    "                    uuid = parts[2]\n",
    "                    processes.append((pid, memory, uuid))\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "                    \n",
    "        return processes\n",
    "    except Exception as e:\n",
    "        print(f\"获取GPU进程出错: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def get_gpu_uuid_mapping():\n",
    "    \"\"\"获取GPU UUID到设备ID的映射\"\"\"\n",
    "    try:\n",
    "        result = subprocess.check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=index,uuid\", \"--format=csv,noheader,nounits\"],\n",
    "            stderr=subprocess.STDOUT,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        uuid_map = {}\n",
    "        for line in result.decode('utf-8').strip().split('\\n'):\n",
    "            if not line.strip() or ',' not in line:\n",
    "                continue\n",
    "                \n",
    "            index, uuid = line.split(',', 1)\n",
    "            uuid_map[uuid.strip()] = index.strip()\n",
    "            \n",
    "        return uuid_map\n",
    "    except Exception as e:\n",
    "        print(f\"获取GPU映射出错: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def parse_elapsed_time(etime):\n",
    "    \"\"\"解析ps命令返回的运行时间格式\"\"\"\n",
    "    try:\n",
    "        # 处理天-时分秒格式 (e.g., \"3-08:31:03\")\n",
    "        if '-' in etime:\n",
    "            days, time_part = etime.split('-')\n",
    "            days = int(days)\n",
    "        else:\n",
    "            days = 0\n",
    "            time_part = etime\n",
    "            \n",
    "        # 处理时分秒格式\n",
    "        time_components = time_part.split(':')\n",
    "        if len(time_components) == 3:  # HH:MM:SS\n",
    "            hours, minutes, seconds = map(int, time_components)\n",
    "        elif len(time_components) == 2:  # MM:SS\n",
    "            hours = 0\n",
    "            minutes, seconds = map(int, time_components)\n",
    "        else:\n",
    "            return \"未知\"\n",
    "            \n",
    "        # 转换为时间字符串\n",
    "        parts = []\n",
    "        if days > 0:\n",
    "            parts.append(f\"{days}天\")\n",
    "        if hours > 0:\n",
    "            parts.append(f\"{hours}时\")\n",
    "        if minutes > 0:\n",
    "            parts.append(f\"{minutes}分\")\n",
    "        if seconds > 0 or not parts:\n",
    "            parts.append(f\"{seconds}秒\")\n",
    "            \n",
    "        return ''.join(parts)\n",
    "    except Exception:\n",
    "        return \"未知\"\n",
    "\n",
    "def get_process_elapsed_time(pid):\n",
    "    \"\"\"获取进程运行时间\"\"\"\n",
    "    try:\n",
    "        result = subprocess.check_output(\n",
    "            [\"ps\", \"-p\", str(pid), \"-o\", \"etime=\"],\n",
    "            stderr=subprocess.STDOUT,\n",
    "            timeout=5\n",
    "        )\n",
    "        etime = result.decode('utf-8').strip()\n",
    "        return parse_elapsed_time(etime) if etime else \"未知\"\n",
    "    except Exception:\n",
    "        return \"未知\"\n",
    "\n",
    "def get_process_command(pid):\n",
    "    \"\"\"获取进程完整命令行\"\"\"\n",
    "    try:\n",
    "        result = subprocess.check_output(\n",
    "            [\"ps\", \"-p\", str(pid), \"-o\", \"args=\"],\n",
    "            stderr=subprocess.STDOUT,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.decode('utf-8').strip() or \"未知命令\"\n",
    "    except Exception:\n",
    "        return \"未知命令\"\n",
    "\n",
    "def display_gpu_processes():\n",
    "    \"\"\"显示GPU进程信息\"\"\"\n",
    "    # 获取查询时间\n",
    "    query_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"查询时间: {query_time}\\n\")\n",
    "    \n",
    "    # 获取GPU和进程信息\n",
    "    processes = get_gpu_processes()\n",
    "    uuid_map = get_gpu_uuid_mapping()\n",
    "    \n",
    "    # 打印表头\n",
    "    print(f\"{'显卡ID':<8}{'CUDA设备':<12}{'PID':<10}{'显存(MB)':<12}{'运行时间':<18}{'进程信息'}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    if not processes:\n",
    "        print(\"未找到占用GPU显存的进程\")\n",
    "        return\n",
    "        \n",
    "    for pid, memory, uuid in processes:\n",
    "        gpu_id = uuid_map.get(uuid, \"未知\")\n",
    "        cuda_device = f\"cuda:{gpu_id}\" if gpu_id != \"未知\" else \"未知设备\"\n",
    "        elapsed_time = get_process_elapsed_time(pid)\n",
    "        cmd = get_process_command(pid)\n",
    "        \n",
    "        print(f\"{gpu_id:<8}{cuda_device:<12}{pid:<10}{memory:<12}{elapsed_time:<18}{cmd}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    display_gpu_processes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8215a92b-a473-46f7-94f7-dd7020b8bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载文件时发生错误: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "file_path = \"/mnt/gemlab_data_2/User_database/zhushiwei/PHASE/PreceptGuide/features/0a75b377181b60efd8278bce0b6260a5.pt\"  \n",
    "try:\n",
    "    # 明确设置 weights_only=False 以处理包含自定义对象的文件\n",
    "    data = torch.load(file_path, weights_only=False)  \n",
    "    print(\"文件加载成功，加载内容的类型为:\", type(data))\n",
    "except Exception as e:\n",
    "    print(\"加载文件时发生错误:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236cfe6b-70db-4308-90af-69c01b0826e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5766432743171745"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "(20-5*2.28)/math.sqrt(5*2.28*0.9772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd86974-f4fe-45cb-855a-4736a9b0aa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546.8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3000-700-750-3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3444686-aa5a-4ef2-9d1e-d402c4705510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
